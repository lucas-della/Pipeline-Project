{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5036f6",
   "metadata": {},
   "source": [
    "# üßπ Corre√ß√µes ‚Äì Pipeline de KPIs (Parte 1‚Äì3)\n",
    "\n",
    "Este notebook foi gerado como **vers√£o corrigida** para:\n",
    "1) Padronizar a coluna de data (`day` ‚Üí `date`).\n",
    "2) Agregar os KPIs **por dia e `entity` (PF/PJ)**.\n",
    "3) Calcular **TPV, Transactions, Average_Ticket** e **m√©dia m√≥vel de 7 dias (por entidade)**.\n",
    "4) Salvar o arquivo **`data/kpis_gold.csv`** pronto para o app Streamlit.\n",
    "\n",
    "Caso voc√™ deseje incluir mais dimens√µes (ex.: `product`, `payment_method`), basta adicion√°-las no `groupby`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d909d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_PATH: C:\\Users\\lucas\\OneDrive\\√Årea de Trabalho\\Projetos\\CloudWalk-Case\\Operations_analyst_data.csv\n",
      "OUT_FILE: C:\\Users\\lucas\\OneDrive\\√Årea de Trabalho\\Projetos\\CloudWalk-Case\\streamlit\\data\\kpis_gold.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 0) Imports e Config\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho do CSV original (ajuste se necess√°rio)\n",
    "RAW_PATH = Path(\"Operations_analyst_data.csv\")\n",
    "\n",
    "# Caminho de sa√≠da\n",
    "OUT_DIR = Path(\"streamlit/data\")\n",
    "OUT_FILE = OUT_DIR / \"kpis_gold.csv\"\n",
    "\n",
    "print(\"RAW_PATH:\", RAW_PATH.resolve())\n",
    "print(\"OUT_FILE:\", OUT_FILE.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a48e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema ap√≥s padroniza√ß√£o: ['date', 'entity', 'product', 'price_tier', 'anticipation_method', 'payment_method', 'installments', 'amount_transacted', 'quantity_transactions', 'quantity_of_merchants']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 1) Carregar dados brutos\n",
    "# =========================\n",
    "# Observa√ß√£o: Este notebook sup√µe que o CSV original esteja dispon√≠vel em data/transactions.csv\n",
    "# Se o arquivo tiver outro nome/rota, ajuste RAW_PATH acima.\n",
    "\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "\n",
    "# Padronizar nome e tipo da coluna de data\n",
    "date_col_candidates = [c for c in df.columns if c.lower() in (\"day\", \"date\", \"transaction_date\")]\n",
    "if not date_col_candidates:\n",
    "    raise ValueError(\"N√£o encontrei coluna de data (day/date/transaction_date) no CSV. Verifique o schema.\")\n",
    "date_col = date_col_candidates[0]\n",
    "\n",
    "df = df.rename(columns={date_col: \"date\"})\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Checagens b√°sicas\n",
    "expected_cols = [\"entity\",\"amount_transacted\",\"quantity_transactions\"]\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Colunas obrigat√≥rias ausentes no CSV: {missing}. \"\n",
    "                     \"Certifique-se de que o dataset do case foi carregado corretamente.\")\n",
    "print(\"Schema ap√≥s padroniza√ß√£o:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0860cccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>entity</th>\n",
       "      <th>TPV</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Average_Ticket</th>\n",
       "      <th>weekday</th>\n",
       "      <th>TPV_MA7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>PF</td>\n",
       "      <td>1.954255e+07</td>\n",
       "      <td>128784</td>\n",
       "      <td>151.746688</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1.954255e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>PJ</td>\n",
       "      <td>3.244821e+07</td>\n",
       "      <td>633255</td>\n",
       "      <td>51.240353</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3.244821e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>PF</td>\n",
       "      <td>4.961460e+07</td>\n",
       "      <td>162482</td>\n",
       "      <td>305.354411</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3.457857e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>PJ</td>\n",
       "      <td>1.067998e+08</td>\n",
       "      <td>1010708</td>\n",
       "      <td>105.668258</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6.962398e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>PF</td>\n",
       "      <td>4.921404e+07</td>\n",
       "      <td>191736</td>\n",
       "      <td>256.676046</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3.945706e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date entity           TPV  Transactions  Average_Ticket    weekday  \\\n",
       "0 2025-01-01     PF  1.954255e+07        128784      151.746688  Wednesday   \n",
       "1 2025-01-01     PJ  3.244821e+07        633255       51.240353  Wednesday   \n",
       "2 2025-01-02     PF  4.961460e+07        162482      305.354411   Thursday   \n",
       "3 2025-01-02     PJ  1.067998e+08       1010708      105.668258   Thursday   \n",
       "4 2025-01-03     PF  4.921404e+07        191736      256.676046     Friday   \n",
       "\n",
       "        TPV_MA7  \n",
       "0  1.954255e+07  \n",
       "1  3.244821e+07  \n",
       "2  3.457857e+07  \n",
       "3  6.962398e+07  \n",
       "4  3.945706e+07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 2) Agregar KPIs por DIA + ENTITY\n",
    "# =========================\n",
    "# Se quiser incluir outras dimens√µes (product, payment_method etc.), adicione-as no groupby.\n",
    "\n",
    "group_dims = [\"date\", \"entity\"]\n",
    "\n",
    "daily_kpis = (\n",
    "    df.groupby(group_dims, as_index=False)\n",
    "      .agg(\n",
    "          TPV=(\"amount_transacted\", \"sum\"),\n",
    "          Transactions=(\"quantity_transactions\", \"sum\")\n",
    "      )\n",
    ")\n",
    "\n",
    "# KPIs derivados\n",
    "daily_kpis[\"Average_Ticket\"] = daily_kpis.apply(\n",
    "    lambda r: (r[\"TPV\"] / r[\"Transactions\"]) if r[\"Transactions\"] else 0.0, axis=1\n",
    ")\n",
    "\n",
    "# Atributos temporais\n",
    "daily_kpis[\"weekday\"] = daily_kpis[\"date\"].dt.day_name()\n",
    "\n",
    "# Ordena√ß√£o e m√©dia m√≥vel por entidade\n",
    "daily_kpis = daily_kpis.sort_values(group_dims)\n",
    "daily_kpis[\"TPV_MA7\"] = daily_kpis.groupby(\"entity\")[\"TPV\"].transform(lambda s: s.rolling(7, min_periods=1).mean())\n",
    "\n",
    "daily_kpis.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b55a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivo salvo em: C:\\Users\\lucas\\OneDrive\\√Årea de Trabalho\\Projetos\\CloudWalk-Case\\streamlit\\data\\kpis_gold.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 3) Salvar kpis_gold.csv\n",
    "# =========================\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "daily_kpis.to_csv(OUT_FILE, index=False)\n",
    "print(f\"‚úÖ Arquivo salvo em: {OUT_FILE.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f704bc5",
   "metadata": {},
   "source": [
    "\n",
    "## üìå Observa√ß√µes\n",
    "- O arquivo `kpis_gold.csv` cont√©m: `date`, `entity`, `TPV`, `Transactions`, `Average_Ticket`, `weekday`, `TPV_MA7`.\n",
    "- O app **Streamlit** deve agora conseguir filtrar **PF / PJ / Ambos** e recalcular os alertas por dia da semana ap√≥s aplicar os filtros.\n",
    "- Para adicionar **outras dimens√µes** (ex.: `product`, `payment_method`, `price_tier`, `installments`), inclua-as na lista `group_dims` e reexecute a c√©lula de agrega√ß√£o.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
